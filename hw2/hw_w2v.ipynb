{"cells":[{"metadata":{"id":"5G_yOJ1D-QHx","trusted":false},"cell_type":"code","source":"import json\nimport random\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.manifold import TSNE\n\n\nimport torch\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 15","execution_count":null,"outputs":[]},{"metadata":{"id":"L3XU5Xbf-QH3"},"cell_type":"markdown","source":"# Что делать?\nГде есть пометка # CODE писать код\n\n[Полезный туториал](http://jalammar.github.io/illustrated-word2vec/)"},{"metadata":{"id":"4VP5zvVM-QH4"},"cell_type":"markdown","source":"# Загружаем данные\nОни уже обработанные и токенизированные. Процесс можно посмотреть в тетрадке 1.1 Processing corpus"},{"metadata":{"id":"UrgX28uV-QH5","trusted":false},"cell_type":"code","source":"with open('processed_corpus.json', encoding='utf-8') as f:\n    corpus = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"id":"OhqGiU2D-QH_","outputId":"92a6c611-be1c-44ab-f60b-5b22ef665322","trusted":false},"cell_type":"code","source":"len(corpus)","execution_count":null,"outputs":[]},{"metadata":{"id":"adNZ8Yxc-QID","outputId":"89a8cc8e-050c-4e47-f74d-1c80ae9ad841","trusted":false},"cell_type":"code","source":"for text in corpus[:5]:\n    print(' '.join(text))","execution_count":null,"outputs":[]},{"metadata":{"id":"LNKVunXM-QIG"},"cell_type":"markdown","source":"# CBOW"},{"metadata":{"id":"R50QZw0b-QIH","trusted":false},"cell_type":"code","source":"sample_text = corpus[1]","execution_count":null,"outputs":[]},{"metadata":{"id":"k7omSPmL-QIK","outputId":"976094d4-ca53-4695-bcc9-8c8e62a813bb","trusted":false},"cell_type":"code","source":"' '.join(sample_text)","execution_count":null,"outputs":[]},{"metadata":{"id":"II1TuCWB-QIP"},"cell_type":"markdown","source":"# Реализуйте разделение предложения на примеры методом CBOW"},{"metadata":{"id":"q3dKMYZs-QIQ","trusted":false},"cell_type":"code","source":"def cbow_split(tokens, window, pad_token='PAD'):\n    \n    splits = []\n    \n    for i, token in enumerate(tokens):\n        left = []\n        right = []\n        for w in range(window, 0, -1):\n            if i-w>=0:\n                left.append(tokens[i-w])\n            else:\n                left.append(pad_token)\n        for w in range(1, window+1):\n            try:\n                right.append(tokens[i+w])\n            except:\n                right.append(pad_token)\n        split = (left, token, right)\n        splits.append(split)\n    return splits","execution_count":null,"outputs":[]},{"metadata":{"id":"Jv7K7nlC-QIT","trusted":false},"cell_type":"code","source":"splits = cbow_split(sample_text, window=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"3G70kiYH-QIV","outputId":"bc42b171-1efd-4c17-db87-a6232f6ea46d","trusted":false},"cell_type":"code","source":"for sample in splits:\n    print('Левый контекст:', sample[0])\n    print('Центральное слово:', sample[1])\n    print('Правый контекст:', sample[2], end='\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"id":"vCKZKvy7-QIY","outputId":"e98d9b34-a40f-40da-9821-cb8ed9c22deb","trusted":false},"cell_type":"code","source":"splits","execution_count":null,"outputs":[]},{"metadata":{"id":"aE-N4KE2-QIb"},"cell_type":"markdown","source":"# Expected\n\n```python\n[(['PAD', 'PAD'], 'вопрос', ['почему', 'например']),\n (['PAD', 'вопрос'], 'почему', ['например', 'китайский']),\n (['вопрос', 'почему'], 'например', ['китайский', 'японский']),\n (['почему', 'например'], 'китайский', ['японский', 'UNK']),\n (['например', 'китайский'], 'японский', ['UNK', 'PAD']),\n (['китайский', 'японский'], 'UNK', ['PAD', 'PAD'])]\n```"},{"metadata":{"id":"9Mh9d37Y-QIc","outputId":"1ad9557d-84aa-4196-8534-e9d68da96e31","trusted":false},"cell_type":"code","source":"cbow_split(sample_text, window=3)","execution_count":null,"outputs":[]},{"metadata":{"id":"2MPsB1M3-QIg"},"cell_type":"markdown","source":"# Expected\n\n```python\n[(['PAD', 'PAD', 'PAD'], 'вопрос', ['почему', 'например', 'китайский']),\n (['PAD', 'PAD', 'вопрос'], 'почему', ['например', 'китайский', 'японский']),\n (['PAD', 'вопрос', 'почему'], 'например', ['китайский', 'японский', 'UNK']),\n (['вопрос', 'почему', 'например'], 'китайский', ['японский', 'UNK', 'PAD']),\n (['почему', 'например', 'китайский'], 'японский', ['UNK', 'PAD', 'PAD']),\n (['например', 'китайский', 'японский'], 'UNK', ['PAD', 'PAD', 'PAD'])]\n```"},{"metadata":{"id":"SRDakuCO-QIg"},"cell_type":"markdown","source":"# Skipgram"},{"metadata":{"id":"--GIEwWC-QIh","outputId":"56eac1bf-470a-48d6-f010-8295efa834d1","trusted":false},"cell_type":"code","source":"' '.join(sample_text)","execution_count":null,"outputs":[]},{"metadata":{"id":"EmIOWEzr-QIj"},"cell_type":"markdown","source":"# Реализуйте разделение предложения на примеры методом Skipgram"},{"metadata":{"id":"VRTUhCF9-QIk","trusted":false},"cell_type":"code","source":"def skipgram_split(tokens, window):\n    \n    splits = []\n    \n    for i, token in enumerate(tokens):\n        for w in range(window, 0, -1):\n            if i-w>=0:\n                splits.append((tokens[i-w], token))\n        for w in range(1, window+1):\n            try:\n                splits.append((tokens[i+w], token))\n            except:\n                continue\n    \n    return splits","execution_count":null,"outputs":[]},{"metadata":{"id":"e8bepGnq-QIm","trusted":false},"cell_type":"code","source":"splits = skipgram_split(sample_text, window=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"78YE-_m_-QIq","outputId":"b092502b-a234-4dee-9db6-b88e6bac7747","trusted":false},"cell_type":"code","source":"for sample in splits:\n    print('Контекст:', sample[0])\n    print('Центральное слово:', sample[1], end='\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"id":"6AKXoA6H-QIu","outputId":"13568c94-47a5-4f65-c477-53eb84589adb","trusted":false},"cell_type":"code","source":"skipgram_split(sample_text, window=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"hMPt7qR3-QIx"},"cell_type":"markdown","source":"# Expected\n\n```python\n[('почему', 'вопрос'),\n ('например', 'вопрос'),\n ('вопрос', 'почему'),\n ('например', 'почему'),\n ('китайский', 'почему'),\n ('вопрос', 'например'),\n ('почему', 'например'),\n ('китайский', 'например'),\n ('японский', 'например'),\n ('почему', 'китайский'),\n ('например', 'китайский'),\n ('японский', 'китайский'),\n ('UNK', 'китайский'),\n ('например', 'японский'),\n ('китайский', 'японский'),\n ('UNK', 'японский'),\n ('китайский', 'UNK'),\n ('японский', 'UNK')]\n```"},{"metadata":{"id":"uLoNs70i-QIy","outputId":"0b38f63c-b8a7-40d7-f8b5-13a42051437f","trusted":false},"cell_type":"code","source":"skipgram_split(sample_text, window=3)","execution_count":null,"outputs":[]},{"metadata":{"id":"Y7nZAbHp-QI1"},"cell_type":"markdown","source":"# Expected\n\n```python\n[('почему', 'вопрос'),\n ('например', 'вопрос'),\n ('китайский', 'вопрос'),\n ('вопрос', 'почему'),\n ('например', 'почему'),\n ('китайский', 'почему'),\n ('японский', 'почему'),\n ('вопрос', 'например'),\n ('почему', 'например'),\n ('китайский', 'например'),\n ('японский', 'например'),\n ('UNK', 'например'),\n ('вопрос', 'китайский'),\n ('почему', 'китайский'),\n ('например', 'китайский'),\n ('японский', 'китайский'),\n ('UNK', 'китайский'),\n ('почему', 'японский'),\n ('например', 'японский'),\n ('китайский', 'японский'),\n ('UNK', 'японский'),\n ('например', 'UNK'),\n ('китайский', 'UNK'),\n ('японский', 'UNK')]\n```"},{"metadata":{"id":"DDMKBdEJ-QI1","trusted":false},"cell_type":"code","source":"word2index = {}\n\nfor text in corpus:\n    for token in text:\n        if token not in word2index:\n            word2index[token] = len(word2index)","execution_count":null,"outputs":[]},{"metadata":{"id":"yIvJ6xNH-QI4","outputId":"bfb76874-42cc-4f2d-8118-5ebbadc11ad0","trusted":false},"cell_type":"code","source":"len(word2index)","execution_count":null,"outputs":[]},{"metadata":{"id":"qUQUyp6_-QI6","outputId":"1d0e9f21-bbf2-4ff7-86d7-86c0d1eb621e","trusted":false},"cell_type":"code","source":"word2index['UNK']","execution_count":null,"outputs":[]},{"metadata":{"id":"93vw0mZJ-QI-","outputId":"edd2986a-c299-4adb-920d-06800cb1ea24","trusted":false},"cell_type":"code","source":"[word2index[tok] if tok in word2index else word2index['UNK'] for tok in 'мама мыть рама'.split()]","execution_count":null,"outputs":[]},{"metadata":{"id":"YPVqQz1Q-QJA"},"cell_type":"markdown","source":"# Torch Dataset\nВ торче есть очень удобная читалка данных"},{"metadata":{"id":"9JmOp6tl-QJB","trusted":false},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"id":"un1I9-Oq-QJE","trusted":false},"cell_type":"code","source":"# игрушечный датасет\n# 121535 примера, 4 фичи, 3 класса\nsome_data_x = np.random.rand(121535, 4)\nsome_data_y = np.random.randint(3, size=(121535,))","execution_count":null,"outputs":[]},{"metadata":{"id":"LKMdwZoj-QJH","outputId":"318064a4-8839-4357-a313-0ee03a751623","trusted":false},"cell_type":"code","source":"# соверешенно игрушечный, просто цифры\nsome_data_x[:10]","execution_count":null,"outputs":[]},{"metadata":{"id":"vM5hdTHL-QJK","outputId":"be36760c-4392-476c-9b01-2fbddf561913","trusted":false},"cell_type":"code","source":"some_data_y","execution_count":null,"outputs":[]},{"metadata":{"id":"hYPnj8Zx-QJO","trusted":false},"cell_type":"code","source":"class ToyDataset(Dataset):\n    \n    def __init__(self, data_x, data_y):\n        \n        super().__init__()\n        \n        self.data_x = data_x\n        self.data_y = data_y\n        \n    def __len__(self):\n        \n        # Нужно обязательно определить эту функцию\n        # Должна возвращать размер датасета\n        \n        return len(self.data_x)\n    \n    def __getitem__(self, idx):\n        \n        # Еще нужно определить этот метод\n        # То есть как мы будем доставать наши данные по индексу\n        \n        return self.data_x[idx], self.data_y[idx]","execution_count":null,"outputs":[]},{"metadata":{"id":"a_MZLTRu-QJR","trusted":false},"cell_type":"code","source":"some_dataset = ToyDataset(some_data_x, some_data_y)","execution_count":null,"outputs":[]},{"metadata":{"id":"kUG1lA1Q-QJT","outputId":"58f4b50a-dfa4-42f6-9b88-d34b5ea10436","trusted":false},"cell_type":"code","source":"some_dataset[5], some_dataset[467]","execution_count":null,"outputs":[]},{"metadata":{"id":"cop_MFeU-QJW","trusted":false},"cell_type":"code","source":"some_loader = DataLoader(some_dataset, batch_size=16, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"DQk7bsfl-QJZ","outputId":"7f5e35ee-2475-4274-df31-f16c17f23fb7","trusted":false},"cell_type":"code","source":"for x, y in some_loader:\n    break\n    \nlen(x), x","execution_count":null,"outputs":[]},{"metadata":{"id":"tk9UYoAZ-QJb","outputId":"b47abc67-9807-4049-aae6-a0fc8f736057","trusted":false},"cell_type":"code","source":"for x, y in some_loader:\n    pass\n\nlen(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"mKcDHQmQ-QJd","outputId":"1db142af-fc59-4a55-edfc-2b6a0629e520","trusted":false},"cell_type":"code","source":"# почему 13?\n# потому что количество наших данных нацело не делится на 16\n# и поэтому последний батч меньше 16-ти\nlen(some_dataset) % 16","execution_count":null,"outputs":[]},{"metadata":{"id":"tKB5HOaD-QJf"},"cell_type":"markdown","source":"# А зачем?"},{"metadata":{"id":"W0yoSNF--QJg","trusted":false},"cell_type":"code","source":"class ToyDataset(Dataset):\n    \n    def __init__(self, data_x, data_y):\n        \n        super().__init__()\n        \n        self.data_x = data_x\n        self.data_y = data_y\n        \n    def __len__(self):\n        \n        # Нужно обязательно определить эту функцию\n        # Должна возвращать размер датасета\n        \n        return len(self.data_x)\n    \n    @staticmethod\n    def add_pow_features(x, n=2):\n        \n        return np.concatenate([x, x ** n]) \n    \n    @staticmethod\n    def add_log_features(x):\n        \n        return np.concatenate([x, np.log(x)]) \n    \n    def __getitem__(self, idx):\n        \n        # Еще нужно определить этот метод\n        # То есть как мы будем доставать наши данные по индексу\n        \n        x = self.data_x[idx]\n        \n        # внутри датасета мы можем делать все что угодно с нашими данными\n        # например выше определим функции, которые добавляют степенные фичи\n        x = self.add_pow_features(x, n=2)\n        x = self.add_pow_features(x, n=3)\n        # и еще возьмем логарифмические фичи\n        x = self.add_log_features(x)\n        \n        y = self.data_y[idx]\n        \n        return x, y","execution_count":null,"outputs":[]},{"metadata":{"id":"Z3-zX3W9-QJi","trusted":false},"cell_type":"code","source":"toy_dataset = ToyDataset(some_data_x, some_data_y)","execution_count":null,"outputs":[]},{"metadata":{"id":"j5Gv9VId-QJj","trusted":false},"cell_type":"code","source":"toy_loader = DataLoader(dataset=toy_dataset, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"id":"PPL5U_8j-QJn","trusted":false},"cell_type":"code","source":"for x, y in toy_loader:\n    break","execution_count":null,"outputs":[]},{"metadata":{"id":"Hk2Jq5AM-QJr","outputId":"8c2a7f22-b2a7-4519-f1f9-c640c15c2688","trusted":false},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"_WzcytyJ-QJt","outputId":"adcf8be1-e7f3-498d-ac26-a2aca086cea8","trusted":false},"cell_type":"code","source":"# заметим, что мы сразу получаем торчовый формат данных\nx","execution_count":null,"outputs":[]},{"metadata":{"id":"2dXXYUeh-QJw","outputId":"cc12ca29-ed5d-49ca-98d2-146835dc4f49","trusted":false},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"id":"Tcu7YNmP-QJz"},"cell_type":"markdown","source":"# Если вы ничего здесь не понимаете, то вернитесь в конец первой домашки, там все объясняется"},{"metadata":{"id":"yyiaOPCH-QJ0","trusted":false},"cell_type":"code","source":"model = torch.nn.Sequential(torch.nn.Linear(32, 16),\n                            torch.nn.ReLU(),\n                            torch.nn.Linear(16, 8),\n                            torch.nn.ReLU(),\n                            torch.nn.Linear(8, 3))\n\ncriterion = torch.nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"id":"v5SG0GwV-QJ2","outputId":"c5e44881-b22f-497e-b783-6b551226fb9b","trusted":false},"cell_type":"code","source":"with torch.no_grad():\n\n    prediction = model(x.float())\n\n    loss = criterion(prediction, y)\n    \nloss.item()","execution_count":null,"outputs":[]},{"metadata":{"id":"SKX3INEj-QJ5"},"cell_type":"markdown","source":"# Боевые датасеты"},{"metadata":{"id":"Wmns3gD_-QJ5","trusted":false},"cell_type":"code","source":"class CBOWDataset(Dataset):\n\n    def __init__(self,\n                 corpus,\n                 word2index,\n                 window=2,\n                 unk_token='UNK',\n                 pad_token='PAD',\n                 collect_verbose=True):\n\n        self.corpus = corpus\n        self.word2index = word2index\n        self.index2word = {value: key for key, value in self.word2index.items()}\n        self.window = window\n\n        self.unk_token = unk_token\n        self.unk_index = self.word2index[self.unk_token]\n\n        self.pad_token = pad_token\n        self.pad_index = len(self.word2index)\n\n        self.collect_verbose = collect_verbose\n\n        self.data = []\n\n        self.collect_data()\n\n    def __len__(self):\n\n        return len(self.data)\n\n    def _split_function(self, tokenized_text):\n\n        splits = []\n\n        for n in range(len(tokenized_text)):\n            left_context = tokenized_text[np.maximum(n - self.window, 0):n]\n            left_context = ([self.pad_index] * (self.window - len(left_context))) + left_context\n\n            central_word = tokenized_text[n]\n\n            right_context = tokenized_text[n + 1:n + self.window + 1]\n            right_context = right_context + ([self.pad_index] * (self.window - len(right_context)))\n\n            splits.append((left_context + right_context, central_word))\n\n        return splits\n\n    def indexing(self, tokenized_text):\n\n        return [self.word2index[token] if token in self.word2index else self.unk_index for token in tokenized_text]\n\n    def collect_data(self):\n\n        corpus = tqdm(self.corpus, disable=not self.collect_verbose)\n\n        for tokenized_text in corpus:\n            indexed_text = self.indexing(tokenized_text)\n            cbow_examples = self._split_function(indexed_text)\n\n            self.data.extend(cbow_examples)\n\n    def __getitem__(self, idx):\n\n        c = self.data[idx]\n\n        context = torch.Tensor(context).long()\n\n        return context, central_word","execution_count":null,"outputs":[]},{"metadata":{"id":"ipg49lQ7-QJ8"},"cell_type":"markdown","source":"# Мы будем учить модель Skipgram\nРеализуйте читалку данных"},{"metadata":{"id":"HMoiHkoG-QJ8","trusted":false},"cell_type":"code","source":"class SkipgramDataset(Dataset):\n\n    def __init__(self,\n                 corpus,\n                 word2index,\n                 window=2,\n                 unk_token='UNK',\n                 collect_verbose=True):\n\n        self.corpus = corpus\n        self.word2index = word2index\n        self.index2word = {value: key for key, value in self.word2index.items()}\n        self.window = window\n        self.unk_token = unk_token\n        self.unk_index = self.word2index[self.unk_token]\n        self.collect_verbose = collect_verbose\n        self.data = []\n        self.collect_data()\n\n    def __len__(self):\n\n        return len(self.data)\n\n    def _split_function(self, tokenized_text):\n        \n        # CODE\n        \n        # вставить здесь функцию, которые вы писали раньше\n\n        splits = []\n    \n        for i, token in enumerate(tokenized_text):\n            for w in range(self.window, 0, -1):\n                if i-w>=0:\n                    splits.append((tokenized_text[i-w], token))\n            for w in range(1, self.window+1):\n                try:\n                    splits.append((tokenized_text[i+w], token))\n                except:\n                    continue\n        return splits\n\n    def indexing(self, tokenized_text):\n\n        return [self.word2index[token] if token in self.word2index else self.unk_index for token in tokenized_text]\n\n    def collect_data(self):\n\n        corpus = tqdm(self.corpus, disable=not self.collect_verbose)\n\n        for tokenized_text in corpus:\n            indexed_text = self.indexing(tokenized_text)\n            \n            skipgram_examples = self._split_function(indexed_text)\n            self.data.extend(skipgram_examples)\n\n    def __getitem__(self, idx):\n        \n        # CODE\n        context, central_word = self.data[idx]\n        #context = torch.Tensor(context).long()\n\n        return context, central_word","execution_count":null,"outputs":[]},{"metadata":{"id":"Lrm5FgMH-QKD","scrolled":true,"outputId":"a7197249-32d0-4d37-89ed-557f29cc4594","trusted":false},"cell_type":"code","source":"dataset = SkipgramDataset(corpus, word2index)","execution_count":null,"outputs":[]},{"metadata":{"id":"7FNrhfKs-QKH","trusted":false},"cell_type":"code","source":"BATCH_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{"id":"aDJlS08d-QKK","trusted":false},"cell_type":"code","source":"dataset_loader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"id":"FbuMId0w-QKN","trusted":false},"cell_type":"code","source":"for x, y in dataset_loader:\n    break","execution_count":null,"outputs":[]},{"metadata":{"id":"m1xzZcLL-QKQ","outputId":"778f8f13-7244-4e8a-9faa-bb0abdb0c99b","trusted":false},"cell_type":"code","source":"x[:5]","execution_count":null,"outputs":[]},{"metadata":{"id":"7ujTAeG--QKS","outputId":"cf6cca07-8b4c-4aac-9b71-4a48dd03d018","trusted":false},"cell_type":"code","source":"y[:5]","execution_count":null,"outputs":[]},{"metadata":{"id":"yAwyMnwy-QKY","outputId":"183dc941-f810-444f-d648-fdaabec9a77a","trusted":false},"cell_type":"code","source":"x.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"mdHSNp7o-QKa","trusted":false},"cell_type":"code","source":"class CBOW(torch.nn.Module):\n    \n    def __init__(self, vocab_size, embedding_dim, pad_index):\n        \n        super().__init__()\n        \n        if pad_index > 0:\n            vocab_size += 1\n        \n        self.in_embedding = torch.nn.Embedding(num_embeddings=vocab_size, \n                                               embedding_dim=embedding_dim,\n                                               padding_idx=pad_index)\n        \n        self.out_embedding = torch.nn.Linear(in_features=embedding_dim,\n                                             out_features=vocab_size, bias=False)\n        \n    def forward(self, x):\n        \n        x = self.in_embedding(x).sum(dim=-2)\n        x = self.out_embedding(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"id":"qzdleAah-QKc"},"cell_type":"markdown","source":"# Мы будем учить модель Skipgram\nРеализуйте ее"},{"metadata":{"id":"Infjs9ERkMwk","trusted":false},"cell_type":"code","source":"class CBOW(torch.nn.Module):\n    \n    def __init__(self, vocab_size, embedding_dim, pad_index):\n        \n        super().__init__()\n        \n        if pad_index > 0:\n            vocab_size += 1\n        \n        self.in_embedding = torch.nn.Embedding(num_embeddings=vocab_size, \n                                               embedding_dim=embedding_dim,\n                                               padding_idx=pad_index)\n        \n        self.out_embedding = torch.nn.Linear(in_features=embedding_dim,\n                                             out_features=vocab_size, bias=False)\n        \n    def forward(self, x):\n        \n        x = self.in_embedding(x).sum(dim=-2)\n        x = self.out_embedding(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"id":"dEPOYYtO-QKc","trusted":false},"cell_type":"code","source":"# CODE\nclass SkipGram(torch.nn.Module):\n    def  __init__(self, vocab_size, embedding_dim):\n        super().__init__()\n\n        self.in_embedding = torch.nn.Embedding(num_embeddings=vocab_size, \n                                               embedding_dim=embedding_dim)\n        \n        self.out_embedding =  torch.nn.Linear(in_features=embedding_dim,\n                                             out_features=vocab_size, bias=False)\n    def forward(self, x):\n\n        x = self.in_embedding(x)\n        x = self.out_embedding(x)\n        return x\n","execution_count":null,"outputs":[]},{"metadata":{"id":"RQ5-Dlp2-QKk","trusted":false},"cell_type":"code","source":"# размерность эмбеддинга\n# маленькая, чтобы мы могли недолго поучить ворд2век и увидеть результаты\nEMBEDDING_DIM = 20","execution_count":null,"outputs":[]},{"metadata":{"id":"UjRBBMc_-QKm","trusted":false},"cell_type":"code","source":"model = SkipGram(vocab_size=len(word2index), embedding_dim=EMBEDDING_DIM)","execution_count":null,"outputs":[]},{"metadata":{"id":"B_ax0fCnlXaw","outputId":"7ab0876d-8e58-4e1b-a480-08f7ee8363de","trusted":false},"cell_type":"code","source":"with torch.no_grad():\n    pred = model(x)\n\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"OmCJKQZq-QKo","outputId":"70a38462-4443-4b93-9dee-68ae04f00abb","trusted":false},"cell_type":"code","source":"with torch.no_grad():\n    pred = model(x)\n\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"u9jB8Ts5-QKs","trusted":false},"cell_type":"code","source":"optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n\n# aka loss function\ncriterion = torch.nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"id":"YtrckfVV-QKt"},"cell_type":"markdown","source":"# Допишите обучалку"},{"metadata":{"id":"jIwRR0wQ-QKu","outputId":"ecec7b08-2fb3-46ef-bca3-4219a5e132e8","trusted":false},"cell_type":"code","source":"epochs = 3\n\nlosses = []\n\nfor n_epoch in range(epochs):\n\n    try:\n\n        progress_bar = tqdm(total=len(dataset_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n\n        for x, y in dataset_loader:\n\n            # CODE\n            optimizer.zero_grad()\n        \n            pred = model(x)\n        \n            loss = criterion(pred, y)\n        \n            loss.backward()\n        \n            optimizer.step()\n\n            losses.append(loss.item())\n\n            progress_bar.set_postfix(loss=np.mean(losses[-100:]))\n\n            progress_bar.update(x.shape[0])\n\n        progress_bar.close()\n\n    except KeyboardInterrupt:\n\n        progress_bar.close()\n        break","execution_count":null,"outputs":[]},{"metadata":{"id":"7XSyh32AcFnX","outputId":"f1464dda-7ccc-4e37-c173-697207f5478e","trusted":false},"cell_type":"code","source":"plt.title('SkipGram Training Process')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.grid()\nplt.plot(losses)","execution_count":null,"outputs":[]},{"metadata":{"id":"p_6jlTA9-QK4","trusted":false},"cell_type":"code","source":"# проверка, что хоть что-то выучилось\nassert np.mean(losses[-1000:]) < 7.5","execution_count":null,"outputs":[]},{"metadata":{"id":"sKPNkEV9-QK6","trusted":false},"cell_type":"code","source":"embedding_matrix = model.in_embedding.weight.detach()","execution_count":null,"outputs":[]},{"metadata":{"id":"gaX822kS-QK8","trusted":false},"cell_type":"code","source":"def cos_sim(embedding_matrix, token2id, word1, word2):\n    \n    i1 = token2id[word1]\n    i2 = token2id[word2]\n    \n    v1, v2 = embedding_matrix[i1], embedding_matrix[i2]\n    \n    v1_n = v1.div(v1.norm(keepdim=True))\n    v2_n = v2.div(v2.norm(keepdim=True))\n    \n    similarity = torch.dot(v1_n, v2_n).item()\n    \n    return similarity","execution_count":null,"outputs":[]},{"metadata":{"id":"R21DdmvA-QK-"},"cell_type":"markdown","source":"# Косинусная близость\nОт 0 до 1, где 0 - вектора абсолютно разные, где 1 - идентичные."},{"metadata":{"id":"DZ6CN7ve-QK-","outputId":"dc273486-20ed-4061-eecc-5daf95f99de3","trusted":false},"cell_type":"code","source":"cos_sim(embedding_matrix, word2index, 'день', 'месяц')","execution_count":null,"outputs":[]},{"metadata":{"id":"vCoixKLe-QLA","outputId":"024768ba-8564-42d5-f56c-2d652b0d19b8","trusted":false},"cell_type":"code","source":"cos_sim(embedding_matrix, word2index, 'минута', 'месяц')","execution_count":null,"outputs":[]},{"metadata":{"id":"Rvbcwc1v-QLD","outputId":"b88cad3e-503d-47ce-9a71-a0714f7380e3","trusted":false},"cell_type":"code","source":"cos_sim(embedding_matrix, word2index, 'сотрудник', 'сотрудница')","execution_count":null,"outputs":[]},{"metadata":{"id":"EDIjBUAf-QLF","outputId":"f00b7406-6241-42d2-b9f5-5ef8ea785bd6","trusted":false},"cell_type":"code","source":"cos_sim(embedding_matrix, word2index, 'вклад', 'перевод')","execution_count":null,"outputs":[]},{"metadata":{"id":"k2DhdbuP-QLL","outputId":"473e6ceb-d741-4134-abc6-679fbd13df67","trusted":false},"cell_type":"code","source":"random_word = random.choice(list(word2index.keys()))\nsim = cos_sim(embedding_matrix, word2index, 'день', random_word)\n'Косинусная близость слова \"день\" к случайному выбраному слову \"{}\" равна {:.3f}'.format(random_word, sim)","execution_count":null,"outputs":[]},{"metadata":{"id":"lEPIxy9H-QLN","trusted":false},"cell_type":"code","source":"freq = {}\n\nfor text in corpus:\n    for token in text:\n        if token in freq:\n            freq[token] += 1\n        else:\n            freq[token] = 1","execution_count":null,"outputs":[]},{"metadata":{"id":"oP54xg1l-QLP","trusted":false},"cell_type":"code","source":"sorted_freq = [(k, freq[k]) for k in sorted(freq, key=freq.get, reverse=True)]\ntop_sorted_freq = sorted_freq[0:200]","execution_count":null,"outputs":[]},{"metadata":{"id":"VEsBALPR-QLR","outputId":"faefa6bb-991d-42c1-f0bd-2bc29884c8d7","trusted":false},"cell_type":"code","source":"tsne = TSNE(n_components=2, init='pca', random_state=42, verbose=2)\nreduced = tsne.fit_transform(embedding_matrix)","execution_count":null,"outputs":[]},{"metadata":{"id":"r7RrwimP-QLS","trusted":false},"cell_type":"code","source":"top_words = [a for a,_ in top_sorted_freq]","execution_count":null,"outputs":[]},{"metadata":{"id":"oU6LKHNY-QLU","trusted":false},"cell_type":"code","source":"inds = [word2index[word] for word in top_words]\nx_coords = [coords[0] for coords in reduced[inds]]\ny_coords = [coords[1] for coords in reduced[inds]]","execution_count":null,"outputs":[]},{"metadata":{"id":"2K7mEN6XjK3j","outputId":"d3ebdf91-8717-47a1-fce6-b58ffc6239fb","trusted":false},"cell_type":"code","source":"for (x, y, word) in zip(x_coords, y_coords, top_words):\n    plt.scatter(x, y, marker='.', color='blue')\n    plt.text(x+0.01, y+0.01, word, fontsize=9)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
